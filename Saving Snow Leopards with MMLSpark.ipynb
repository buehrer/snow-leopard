 sfasdfasdf {"cells":[{"cell_type":"markdown","source":["## Snow Leopard Detection in 5 minutes with the Azure Machine Learning Workbench\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/SLT.png\" width=\"600\"/>"],"metadata":{"hideCode":false,"hidePrompt":false,"slideshow":{"slide_type":"-"}}},{"cell_type":"markdown","source":["#### There's only 4000-8000 Snow Leopards left in the wild. They face constant threats from: \n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/threats.png\" width=\"800\"/>\n\n#### Because they are so rare, we know very little about their behavior, habbitat, or population dynamics. \n#### To protect these creatures and their habitat we need reliable data."],"metadata":{}},{"cell_type":"markdown","source":["#### The Snow Leopard Trust has been monitoring leopards using a remote camera system for ~9 years.\n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/camera_trap.jpg\" width=\"500\"/>"],"metadata":{}},{"cell_type":"markdown","source":["#### They have gathered over 1.3 million images, but 90% of them are goats.\n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/trap_images.png\" width=\"1900\"/>\n\n#### It will take >20,000 hours to manually find all of the leopards in the dataset."],"metadata":{}},{"cell_type":"markdown","source":["#### We will build our detection system with Microsoft's new open-source, distributed deep-learning library: \n\n<a href=\"https://github.com/Azure/mmlspark\"><img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/mmlspark.png\" width=\"600\"/></a>"],"metadata":{"hideCode":false,"hidePrompt":false}},{"cell_type":"code","source":["import mmlspark as mml\n\nimport pyspark\nfrom pyspark.ml import  PipelineModel\nfrom pyspark.ml.classification import LogisticRegression\nimport os"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#### First we will load and split the data into training and test sets"],"metadata":{"hideCode":false,"hidePrompt":false}},{"cell_type":"code","source":["wasbRoot = \"wasb://amlperf2container1@amlbigdemo.blob.core.windows.net/\"\nimages = spark.read.parquet(wasbRoot + \"datasets/labelledSnowLeopardData.parquet\")\ncamerasTrain, camerasTest = images.select(\"camera\").distinct().randomSplit([.8, .2], seed=1)\ntrain = images.join(broadcast(camerasTrain), \"camera\").cache()\ntest = images.join(broadcast(camerasTest), \"camera\").cache()"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### We use transfer learning to create a Snow Leopard detector that doesen't require millions of labelled training examples \n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/network_2.png\" width=\"900\"/>"],"metadata":{"hideCode":false,"hidePrompt":false}},{"cell_type":"code","source":["# Download the model from our repository of trained models\nnetwork = mml.ModelDownloader(spark, wasbRoot + \"Models/\").downloadByName(\"ResNet50\")\n\n#Create the truncated network\nfeaturizer = mml.ImageFeaturizer(inputCol=\"image\", outputCol=\"features\", cutOutputLayers=2).setModel(network)\n\n# Add the logistic regression\nclassifier = LogisticRegression(featuresCol = \"features\", labelCol=\"label\",\n                                predictionCol=\"pred\", probabilityCol=\"prob\")\ndc = mml.DropColumns(cols=[\"image\", \"features\"]) \n\n# Stich it all together into a single pipeline\nmodel = Pipeline(stages=[featurizer, classifier, dc])"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":["fitModel = model.fit(train)\npredictions = fitModel.transform(test).cache()    "],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":11},{"cell_type":"code","source":["fig = plt.figure(figsize=(4.5, 4.5))\nmml.plot.confusionMatrix(predictions, 'label', 'pred', ['No Leopard', 'Leopard'])\ndisplay(fig)"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# Stream from a kafka topic\nbrokers= [\"10.0.0.25:9092\", \"10.0.0.26:9092\", \"10.0.0.27:9092\", \"10.0.0.16:9092\"]\nimageStream = spark.streamFromKafka(\"images-aml\", brokers, test.drop(\"label\").schema, 200)\n\n# Classify the incoming data using our trained model\npredictionStream = fitModel.transform(imageStream)\\\n    .drop('rawPrediction').drop('pred')\\\n    .withColumn(\"prob\", mml.get_value_at(\"prob\", 1))\n\n# Stream the results to PowerBI \nq1 = predictionStream.streamToPowerBI(os.environ[\"POWER_BI_URL\"], 10000).start()"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["####  We can stream from Apache Kafka, through our trained network, and out to PowerBI to visualize the results \n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/streaming_3.png\" width=\"700\"/>"],"metadata":{"hideCode":false,"hidePrompt":false}},{"cell_type":"markdown","source":["#### We can now view the PowerBI dashboard and explore our results! \n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/SnowLeopardPowerBI.gif\" width=\"700\"/>"],"metadata":{}},{"cell_type":"code","source":["fitModel.write().overwrite().save(wasbRoot + \"Models/snowLeopardClassifier.mml\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["#### For low latency scoring, we can also deploy to a Kubernetes cluster using the az ml command line:"],"metadata":{}},{"cell_type":"markdown","source":["```bash \naz ml service create realtime \\\n    -f score.py \\\n    --model-file snowLeopardClassifier.mml \\\n    -n leopard_service \\\n    -r spark-py ```"],"metadata":{"hideCode":false,"hidePrompt":false}},{"cell_type":"markdown","source":["####  We can then easily call out to this endpoint from a website: \n\n\n<img src=\"https://amlbigdemo.blob.core.windows.net/public/connect/SnowLeopardWebsite.png\" width=\"700\"/>"],"metadata":{}},{"cell_type":"code","source":["q1.isActive()"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":20},{"cell_type":"code","source":["q1.stop()"],"metadata":{"hideCode":false,"hidePrompt":false},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["####  Where to go for more information :  \n\n- [MMLSpark Github page](https://github.com/Azure/mmlspark)\n\n- [Azure Machine Learning Workbench](https://docs.microsoft.com/en-us/azure/machine-learning/preview/quickstart-installation)\n\n- [Snow Leopard Blog](https://blogs.technet.microsoft.com/machinelearning/2017/06/27/saving-snow-leopards-with-deep-learning-and-computer-vision-on-spark/)\n\n- [Snow Leopard Trust](https://www.snowleopard.org/)\n\n- Whitepages coming soon!"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"SnowLeopardE2E","notebookId":1783457240040535,"kernelspec":{"display_name":"SnowLeopard sparkDemo1","language":"python","name":"snowleopard_sparkdemo1"},"hide_code_all_hidden":false},"nbformat":4,"nbformat_minor":0}
